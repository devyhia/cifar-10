{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hager Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import opencv2 as cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'SURF'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-00562eb5d6fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSURF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'SURF'"
     ]
    }
   ],
   "source": [
    "cv2.SURF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'opencv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4f899f5b349e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopencv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'opencv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import six\n",
    "import opencv2 as cv2\n",
    "from six.moves import range, cPickle\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "(10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "tar_file = tarfile.open(\"cifar-10-python.tar.gz\", 'r:gz')\n",
    "train_batches = []\n",
    "for batch in range(1, 6):\n",
    "    file = tar_file.extractfile(\n",
    "        'cifar-10-batches-py/data_batch_%d' % batch)\n",
    "    try:\n",
    "        if six.PY3:\n",
    "            array = cPickle.load(file, encoding='latin1')\n",
    "        else:\n",
    "            array = cPickle.load(file)\n",
    "        train_batches.append(array)\n",
    "    finally:\n",
    "        file.close()\n",
    "\n",
    "train_features = np.concatenate(\n",
    "    [batch['data'].reshape(batch['data'].shape[0], 3, 32, 32)\n",
    "        for batch in train_batches])\n",
    "train_labels = np.concatenate(\n",
    "    [np.array(batch['labels'], dtype=np.uint8)\n",
    "        for batch in train_batches])\n",
    "train_labels = np.expand_dims(train_labels, 1)\n",
    "# ### Load Testing Dat\n",
    "file = tar_file.extractfile('cifar-10-batches-py/test_batch')\n",
    "try:\n",
    "    if six.PY3:\n",
    "        test = cPickle.load(file, encoding='latin1')\n",
    "    else:\n",
    "        test = cPickle.load(file)\n",
    "finally:\n",
    "    file.close()\n",
    "\n",
    "test_features = test['data'].reshape(test['data'].shape[0], 3, 32, 32)\n",
    "test_labels = np.array(test['labels'], dtype=np.uint8)\n",
    "test_labels = np.expand_dims(test_labels, 1)\n",
    "LABELS = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog',\n",
    "          'horse', 'ship', 'truck']\n",
    "# * 10,000 testing image\n",
    "print(train_features.shape)\n",
    "print(test_features.shape)\n",
    "# ### Data Visualization\n",
    "# Here, you need to note that the image size for `plt.imshow` should be ($width \\times height \\times RGB$) i.e. ($32 \\times 32 \\times 3$). The default is ($3 \\times 32 \\times 32$), that's why I use: `.T` (which is the transpose of $32 \\times 32 \\times 3$ = $3 \\times 32 \\times 32$).\n",
    "# `np.rot90` does 90-degree rotation on the image. `k` is the a multiplier (i.e. if `k=1`, we have 90 deg rotation. If `k=2`, we have 180 deg rotation. If `k=3`, we have 270 deg rotation\n",
    "train_images = np.array([np.rot90(train_features[i].T, k=3) for i in range(0,50000)])           # Train Images\n",
    "test_images = np.array([np.rot90(test_features[i].T, k=3) for i in range(0,10000)])             # Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Extraction part\n",
    "Alldescriptors = [];\n",
    "AllKeypoints = [];\n",
    "ImageSize = 128\n",
    "detector = cv2.SURF()\n",
    "for image in train_images:\n",
    "    resized_image = cv2.resize(image, (ImageSize, ImageSize))             # Images have been resized up to get more features ( a parameter to play with)\n",
    "    keypoints,descriptors = detector.detectAndCompute(resized_image,None)\n",
    "    Out_image = cv2.drawKeypoints(resized_image,keypoints,None,(255,0,0),2)\n",
    "\n",
    "    Alldescriptors.append(descriptors)\n",
    "    AllKeypoints.append(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FLANN parameters\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks=50)   # or pass empty dictionary\n",
    "flann = cv2.FlannBasedMatcher(index_params,search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature matching part\n",
    "N = 10;                     # number of classes we haves\n",
    "BestFeatures = {}           # a dictionary to save best features per class\n",
    "MaxDist = 0.1               # max distance that needs to be there to consider a feature close\n",
    "MaxCount = 1               # MaxCount of features that needs to be there to consider a feature good\n",
    "print(\"Enters the features exploration part\")\n",
    "for label in range(N):\n",
    "    indices = np.where(train_labels == label)\n",
    "    #des1 = Alldescriptors[indices[0][0]]\n",
    "    # get the image that best represents the class ( the one with the Maximum number of features). The other approach was to choose the first image\n",
    "    MaxLength = 0\n",
    "    MaxIndex = 0\n",
    "    for j in range(len(indices[0])):\n",
    "        if len(Alldescriptors[indices[0][j]]) > MaxLength:\n",
    "            MaxLength = len(Alldescriptors[indices[0][j]])\n",
    "            MaxIndex = indices[0][j]\n",
    "    #print MaxLength\n",
    "    #print MaxIndex\n",
    "    des1 = Alldescriptors[MaxIndex]\n",
    "    # Loop over all other images to compare the descriptors\n",
    "    for j in range(len(indices[0])):\n",
    "        if j != MaxIndex:\n",
    "            index = indices[0][j]\n",
    "            des2 = Alldescriptors[index]\n",
    "            counter = 0\n",
    "            AllDesc = []\n",
    "            for x in des1:\n",
    "                counter = 0\n",
    "                for y in des2:\n",
    "                    t = np.subtract(x,y)\n",
    "                    dist = np.sqrt(np.sum(t)**2)           # calculate the distance between two descriptors\n",
    "                    if dist < MaxDist:\n",
    "                        counter = counter + 1\n",
    "                if counter > MaxCount:\n",
    "                    AllDesc.append(x)\n",
    "    BestFeatures[label] = AllDesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dictionary for the best features we got; key represents the label, value represents the descriptors\n",
    "print(len(BestFeatures))\n",
    "print(len(BestFeatures[0]))\n",
    "print(len(BestFeatures[1]))\n",
    "print(len(BestFeatures[2]))\n",
    "print(len(BestFeatures[3]))\n",
    "print(len(BestFeatures[4]))\n",
    "print(len(BestFeatures[5]))\n",
    "print(len(BestFeatures[6]))\n",
    "print(len(BestFeatures[7]))\n",
    "print(len(BestFeatures[8]))\n",
    "print(len(BestFeatures[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
